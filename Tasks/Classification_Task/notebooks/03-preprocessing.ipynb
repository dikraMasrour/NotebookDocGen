{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell-type</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd import numpy as np import ...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>markdown</td>\n",
       "      <td>try to overfit more pls upvote if you fork lik...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>markdown</td>\n",
       "      <td>sub1 0 869</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>markdown</td>\n",
       "      <td>credit very simple code with score 0 886 by ay...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd import numpy as np from sk...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344966</th>\n",
       "      <td>code</td>\n",
       "      <td>POI_data = gpd.read_file(\"../input/geospatial...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344967</th>\n",
       "      <td>markdown</td>\n",
       "      <td>next we create a map from all four geodatafram...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344968</th>\n",
       "      <td>code</td>\n",
       "      <td>ax = counties.plot(figsize=(10,10), color='no...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344969</th>\n",
       "      <td>markdown</td>\n",
       "      <td>it looks like the northeastern part of the sta...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344970</th>\n",
       "      <td>markdown</td>\n",
       "      <td>have questions or comments visit the course di...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332354 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cell-type                                             source  \\\n",
       "0           code  import pandas as pd import numpy as np import ...   \n",
       "1       markdown  try to overfit more pls upvote if you fork lik...   \n",
       "2       markdown                                         sub1 0 869   \n",
       "3       markdown  credit very simple code with score 0 886 by ay...   \n",
       "4           code  import pandas as pd import numpy as np from sk...   \n",
       "...          ...                                                ...   \n",
       "344966      code   POI_data = gpd.read_file(\"../input/geospatial...   \n",
       "344967  markdown  next we create a map from all four geodatafram...   \n",
       "344968      code   ax = counties.plot(figsize=(10,10), color='no...   \n",
       "344969  markdown  it looks like the northeastern part of the sta...   \n",
       "344970  markdown  have questions or comments visit the course di...   \n",
       "\n",
       "                                               title                     tag  \n",
       "0       0-9-try-better-parameters-better-score.ipynb              regression  \n",
       "1       0-9-try-better-parameters-better-score.ipynb              regression  \n",
       "2       0-9-try-better-parameters-better-score.ipynb              regression  \n",
       "3       0-9-try-better-parameters-better-score.ipynb              regression  \n",
       "4       0-9-try-better-parameters-better-score.ipynb              regression  \n",
       "...                                              ...                     ...  \n",
       "344966                          your-first-map.ipynb  reinforcement learning  \n",
       "344967                          your-first-map.ipynb  reinforcement learning  \n",
       "344968                          your-first-map.ipynb  reinforcement learning  \n",
       "344969                          your-first-map.ipynb  reinforcement learning  \n",
       "344970                          your-first-map.ipynb  reinforcement learning  \n",
       "\n",
       "[332354 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_pickle(DATA_PATH + \"text_dataset.pkl\")\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cell-type    0\n",
       "source       0\n",
       "title        0\n",
       "tag          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete raw cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell-type</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cell-type, source, title, tag]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[raw_df['cell-type'] == \"raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['regression', 'classification', 'clustering', 'computer vision',\n",
       "       'nlp', 'reinforcement learning'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.tag.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>import pandas as pd import numpy as np import ...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>try to overfit more pls upvote if you fork lik...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub1 0 869</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credit very simple code with score 0 886 by ay...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>import pandas as pd import numpy as np from sk...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344966</th>\n",
       "      <td>POI_data = gpd.read_file(\"../input/geospatial...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344967</th>\n",
       "      <td>next we create a map from all four geodatafram...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344968</th>\n",
       "      <td>ax = counties.plot(figsize=(10,10), color='no...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344969</th>\n",
       "      <td>it looks like the northeastern part of the sta...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344970</th>\n",
       "      <td>have questions or comments visit the course di...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332354 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   source  \\\n",
       "0       import pandas as pd import numpy as np import ...   \n",
       "1       try to overfit more pls upvote if you fork lik...   \n",
       "2                                              sub1 0 869   \n",
       "3       credit very simple code with score 0 886 by ay...   \n",
       "4       import pandas as pd import numpy as np from sk...   \n",
       "...                                                   ...   \n",
       "344966   POI_data = gpd.read_file(\"../input/geospatial...   \n",
       "344967  next we create a map from all four geodatafram...   \n",
       "344968   ax = counties.plot(figsize=(10,10), color='no...   \n",
       "344969  it looks like the northeastern part of the sta...   \n",
       "344970  have questions or comments visit the course di...   \n",
       "\n",
       "                                               title  \n",
       "0       0-9-try-better-parameters-better-score.ipynb  \n",
       "1       0-9-try-better-parameters-better-score.ipynb  \n",
       "2       0-9-try-better-parameters-better-score.ipynb  \n",
       "3       0-9-try-better-parameters-better-score.ipynb  \n",
       "4       0-9-try-better-parameters-better-score.ipynb  \n",
       "...                                              ...  \n",
       "344966                          your-first-map.ipynb  \n",
       "344967                          your-first-map.ipynb  \n",
       "344968                          your-first-map.ipynb  \n",
       "344969                          your-first-map.ipynb  \n",
       "344970                          your-first-map.ipynb  \n",
       "\n",
       "[332354 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[['source', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.drop(raw_df.index[raw_df['cell-type'] == \"raw\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lang_en(data_ntb):\n",
    "    full_text_md = ''\n",
    "\n",
    "    for i in data_ntb.index:\n",
    "        if data_ntb.loc[i]['cell-type'] == \"markdown\":\n",
    "            full_text_md += str(data_ntb.loc[i]['source']) + \" \"\n",
    "    \n",
    "    if full_text_md == ' ':\n",
    "        return True\n",
    "\n",
    "    elif detect(full_text_md) == 'en':\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_non_en_ntb(data):\n",
    "    L = []\n",
    "    groups = data.groupby('title')\n",
    "    List_ntb = np.unique(data['title'].tolist()).tolist()\n",
    "    for ntb in List_ntb :\n",
    "        try:\n",
    "            if test_lang_en(raw_df[raw_df['title'] == ntb]) != True :\n",
    "                L.append(ntb)\n",
    "                data.drop(data.index[data['title'] == ntb], inplace=True)\n",
    "        except Exception as e:\n",
    "                print(e)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n",
      "No features in text.\n"
     ]
    }
   ],
   "source": [
    "List_non_en_ntb = delete_non_en_ntb(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['active-learning-clustering-dbscan.ipynb',\n",
       " 'analisis-de-genero.ipynb',\n",
       " 'analisis-de-la-super-bowl-y-espectaculos-espa-ol.ipynb',\n",
       " 'analisis-faktor-kebahagiaan.ipynb',\n",
       " 'analyse-subsah.ipynb',\n",
       " 'animal-classification-mobilenetv2-80.ipynb',\n",
       " 'aplica-es-em-nlp-aula-03.ipynb',\n",
       " 'aplica-es-em-nlp-aula-05.ipynb',\n",
       " 'aquarium-dataset-object-detection-in-pytorch.ipynb',\n",
       " 'audio-data-eda-processing-modeling-recommend.ipynb',\n",
       " 'birds-classification-using-mobilenetv2-pytorch.ipynb',\n",
       " 'bitcoin-tweets-sentiment-analysis.ipynb',\n",
       " 'brain-tumor-detection-with-mobilenetv2.ipynb',\n",
       " 'camvid-segmentation-using-unet.ipynb',\n",
       " 'cell-instance-segmentation-unet-eda.ipynb',\n",
       " 'chaii-pytorch-inference-xlmroberta-large.ipynb',\n",
       " 'chaii-qa-multi-lingual-pretrained-baseline.ipynb',\n",
       " 'chap2.ipynb',\n",
       " 'class-2-trend.ipynb',\n",
       " 'classifi-diabetes-by-decisiontree-and-perceptron.ipynb',\n",
       " 'classifica-o-de-documentos-com-doc2vec.ipynb',\n",
       " 'cluster-analysis-of-breast-cancer-dataset.ipynb',\n",
       " 'clustering-analysis-k-means.ipynb',\n",
       " 'clustering.ipynb',\n",
       " 'commonlit-readability-tensorflow-torch-ensemble.ipynb',\n",
       " 'comparing-knn-kmeans-and-kmedoids.ipynb',\n",
       " 'competi-o-final.ipynb',\n",
       " 'conll-huggingface-named-entity-recognition.ipynb',\n",
       " 'connectx-5.ipynb',\n",
       " 'connectx-dengan-deep-q-learning.ipynb',\n",
       " 'cornell-birdcall-identification-1st-place-solution.ipynb',\n",
       " 'credit-top5-solution-evaluation-all.ipynb',\n",
       " 'crime-scale-prediction.ipynb',\n",
       " 'custom-drl-env.ipynb',\n",
       " 'customer-segmentation-clustering-techniques.ipynb',\n",
       " 'customer-segmentation-with-rfm-k-means.ipynb',\n",
       " 'cyclegan-pytorch-lightning.ipynb',\n",
       " 'data-analysis-germany-housing-prices.ipynb',\n",
       " 'data-mining-clustering.ipynb',\n",
       " 'data-mining-project.ipynb',\n",
       " 'data-science-bowl-xgbregressor.ipynb',\n",
       " 'data-science-london-scikit-learn.ipynb',\n",
       " 'decision-markov-process-gridworld-example.ipynb',\n",
       " 'deeplabv3-plus-mobilenetv2-ccf.ipynb',\n",
       " 'deeplabv3-plus-mobilenetv2.ipynb',\n",
       " 'derin-renmenin-temelleri.ipynb',\n",
       " 'dfc2020-unet-indexed-wtloss.ipynb',\n",
       " 'dfuc-efficientnet.ipynb',\n",
       " 'di-engine.ipynb',\n",
       " 'disaster-tweets-analysis.ipynb',\n",
       " 'diy-data-augmentation-with-gpt2.ipynb',\n",
       " 'dogrusal-regresyon.ipynb',\n",
       " 'drd-nn-mobilenetv2.ipynb',\n",
       " 'duygu-analizi-python-nltk-sentiment-analysis.ipynb',\n",
       " 'e-commerce-customers-segmentation.ipynb',\n",
       " 'eda-basico.ipynb',\n",
       " 'eda-indian-liver-patient-records.ipynb',\n",
       " 'eeenet.ipynb',\n",
       " 'efficientnet-model-ensemble-single-tta-inference.ipynb',\n",
       " 'efnetb0-unet-inference.ipynb',\n",
       " 'encuesta-kaggle-2021-espa-a-es-diferente.ipynb',\n",
       " 'epv-peq-aula-1-regress-o.ipynb',\n",
       " 'epv-peq-aula-4-clusteriza-o.ipynb',\n",
       " 'estudio-estadistico-torneo.ipynb',\n",
       " 'exercice-stars-corrig.ipynb',\n",
       " 'facial-expression-classification-with-a-cnn.ipynb',\n",
       " 'fashion-deeplabv3.ipynb',\n",
       " 'faster-rcnn-pytorch.ipynb',\n",
       " 'fasterrcnn-detection.ipynb',\n",
       " 'for-beginner.ipynb',\n",
       " 'fork-of-makine-renmesi-in-lineer-cebir.ipynb',\n",
       " 'fork-of-tugas-clustering.ipynb',\n",
       " 'fork-of-tugas-clusteringg.ipynb',\n",
       " 'gaussianmixture-clustering.ipynb',\n",
       " 'gaussianmixture-july.ipynb',\n",
       " 'gender-recognition-using-svc-randomforest.ipynb',\n",
       " 'generating-song-s-lyrics-gpt-2.ipynb',\n",
       " 'german-credit-topikzulkarnain.ipynb',\n",
       " 'gpt-chatbot.ipynb',\n",
       " 'gpt-finetune.ipynb',\n",
       " 'gpt2-japanese-text-generator.ipynb',\n",
       " 'gpt2-simple.ipynb',\n",
       " 'hitters.ipynb',\n",
       " 'home-depot-int3405.ipynb',\n",
       " 'house-price-predictions.ipynb',\n",
       " 'house-prices-starter-xgb.ipynb',\n",
       " 'huggingface-autonlp.ipynb',\n",
       " 'hungry-geese-reinforcement-learning-approach.ipynb',\n",
       " 'hyun-stacking.ipynb',\n",
       " 'image-captioniong-flickr8k-pytorch.ipynb',\n",
       " 'image-segmentation-with-unet-pytorch.ipynb',\n",
       " 'implementing-linear-regression-on-iris-dataset.ipynb',\n",
       " 'important-code.ipynb',\n",
       " 'inceptionv3-base-line-82-acc-undersampling.ipynb',\n",
       " 'inne-algorytmy-grupowania.ipynb',\n",
       " 'intel-image-classification-mobilenetv2-91.ipynb',\n",
       " 'intro-to-perceptron-and-adaline-linear-neuron.ipynb',\n",
       " 'introdu-o-ao-ml-clustering.ipynb',\n",
       " 'iris-data-with-98-accuracy-score.ipynb',\n",
       " 'iris-dataset-classifier-and-clustering.ipynb',\n",
       " 'k-best-features-xgboost-elasticnet.ipynb',\n",
       " 'k-means-pca-standardscaler-in-python.ipynb',\n",
       " 'k-means-segmentation.ipynb',\n",
       " 'k-nearest-neighbors-knn-from-scratch.ipynb',\n",
       " 'keras-efficientnet.ipynb',\n",
       " 'keras-efficientnetb2-unet-tta-lb-0-88.ipynb',\n",
       " 'kernel4b22f2d02e.ipynb',\n",
       " 'kernel7e4ffba461.ipynb',\n",
       " 'kernel86433682b4.ipynb',\n",
       " 'landmark-recognition-2020-keras.ipynb',\n",
       " 'lb-0-579-yolov5-higher-resolution-f2score.ipynb',\n",
       " 'learning-multimodal.ipynb',\n",
       " 'let-s-try-clr-v3.ipynb',\n",
       " 'leukemia-classification-v1-3-inceptionv3-65-29.ipynb',\n",
       " 'linear-nonlinear-ml.ipynb',\n",
       " 'linear-regression-ridge-ve-lasso-fonksiyonlar.ipynb',\n",
       " 'lineerregresyon.ipynb',\n",
       " 'lstm-cp-clip-nb-tw-tfidf-bert4x-gpt-test-best.ipynb',\n",
       " 'm-ster-big-data-data-science-ucm-text-mining.ipynb',\n",
       " 'machine-learning-tutorial-spr.ipynb',\n",
       " 'machinelearning-training-models.ipynb',\n",
       " 'makine-renmesi-İ-in-lineer-cebir.ipynb',\n",
       " 'mall-clustering.ipynb',\n",
       " 'market-exploration-and-modeling-datagenerator.ipynb',\n",
       " 'maze-rl-qlearning-explanation.ipynb',\n",
       " 'mbart-model7-part-1.ipynb',\n",
       " 'mcdonalds-market-segmentation.ipynb',\n",
       " 'medical-cost-personal-dataset-predict.ipynb',\n",
       " 'metal-cnn-architectures.ipynb',\n",
       " 'methodes-approch-es-remy.ipynb',\n",
       " 'ml-masters-question-classifier.ipynb',\n",
       " 'ml-projet.ipynb',\n",
       " 'mlp-multilayer-perceptron-conceito-b-sico.ipynb',\n",
       " 'mobilenetv2-out-1.ipynb',\n",
       " 'mobilenetv2-out.ipynb',\n",
       " 'mobilenetv2.ipynb',\n",
       " 'motorcycle-dataset.ipynb',\n",
       " 'mountaincar-dqn.ipynb',\n",
       " 'movie-lens-clustering-to-rec.ipynb',\n",
       " 'my-first-object-detection-at-kaggle.ipynb',\n",
       " 'my-logistic-regression-homework.ipynb',\n",
       " 'my-titanic-sub.ipynb',\n",
       " 'nih-chest-xray-draft-4f8e27.ipynb',\n",
       " 'nih-chest-xray-draft-bf3453.ipynb',\n",
       " 'nlp-03.ipynb',\n",
       " 'nlp-chatbot.ipynb',\n",
       " 'nlp-getting-started-electra-pytorch-lightning.ipynb',\n",
       " 'nlp-olist.ipynb',\n",
       " 'nn-lab4-2021-ece-stakias-syllas-kranias.ipynb',\n",
       " 'no-sampler-ensemble-normal-sub-0-7365.ipynb',\n",
       " 'notebook5b264ae426.ipynb',\n",
       " 'notebook66a6eb149d.ipynb',\n",
       " 'notebookbd0faddd09.ipynb',\n",
       " 'object-detection-imageai-yolov3.ipynb',\n",
       " 'olist-nlp.ipynb',\n",
       " 'osic-bayesian-ridge-regression.ipynb',\n",
       " 'p2-datamining-master-ciencia-de-datos-ua-20-21.ipynb',\n",
       " 'pca-svc-ile-el-yaz-s-rakamlar-n-tan-nmas.ipynb',\n",
       " 'plant-diseases-classification-inceptionv3.ipynb',\n",
       " 'plsregression-instant-gratification.ipynb',\n",
       " 'pneumonia-detection-ensemble-vgg16-mobilenetv2.ipynb',\n",
       " 'ppo-lunar-lander-reinforcement-learning.ipynb',\n",
       " 'pppm-stacking-10-models.ipynb',\n",
       " 'preprocessing-new-pipeline-pseudo-model-ensemble.ipynb',\n",
       " 'preprocessing-rapids-finish-in-3-mins.ipynb',\n",
       " 'pretrained-inceptionresnetv2-lb-0-390.ipynb',\n",
       " 'projeto-software-iii.ipynb',\n",
       " 'pulmonary-embolism-pytorch-train.ipynb',\n",
       " 'python-4-randomforest-svc.ipynb',\n",
       " 'pytorch-abnormality-detection.ipynb',\n",
       " 'pytorch-fasterrcnn.ipynb',\n",
       " 'pytorch-inference-birdclef2021-starter.ipynb',\n",
       " 'pytorch-inference-kernel-lazy-tta.ipynb',\n",
       " 'pytorch-moa-0-01867.ipynb',\n",
       " 'pytorchwithbert.ipynb',\n",
       " 'quest-o-5-at-agente-1.ipynb',\n",
       " 'question-answer-npl-exercise.ipynb',\n",
       " 'quora-toxic-questions-classification-18020949.ipynb',\n",
       " 'rain-in-australa-random-forest.ipynb',\n",
       " 'random-actions-only-observation.ipynb',\n",
       " 'readability.ipynb',\n",
       " 'redes-neurais-artificiais-conceito-b-sico.ipynb',\n",
       " 'refactored-bert2-robert1-xlnet1-blend-pseudo1.ipynb',\n",
       " 'reinforcement-learning-part1-only-exploration.ipynb',\n",
       " 'reinforcement-learning-river-raid-atari.ipynb',\n",
       " 'rent-in-main-brazilians-cityes.ipynb',\n",
       " 'resolvido-br-question-answer-dataset-facens.ipynb',\n",
       " 'rnn-basic-gated-recurrentunit-sentiment-analysis.ipynb',\n",
       " 'rossman-regression-correction.ipynb',\n",
       " 'rossmann-store-sale.ipynb',\n",
       " 'salary-predict-with-hitters-data-set.ipynb',\n",
       " 'sample-tpu-xlmr-pytorch-pad-on-fly.ipynb',\n",
       " 'satellite-image-classification.ipynb',\n",
       " 'segmentation-des-clients-d-un-site-e-commerce-nb2.ipynb',\n",
       " 'semi-supervise-anomaly-detection.ipynb',\n",
       " 'sentiment-analysis-naive-bayes.ipynb',\n",
       " 'sentiment-analysis-using-textblob-and-embedding.ipynb',\n",
       " 'seq2seq-chatbot-keras-with-attention.ipynb',\n",
       " 'simple-2d-cnn-classifier-with-pytorch.ipynb',\n",
       " 'simple-cnn-classifier-with-pytorch.ipynb',\n",
       " 'skipgrampretrain-multi-task-learning.ipynb',\n",
       " 'social-distancing-detector.ipynb',\n",
       " 'spam-detection-with-deep-learning-methods.ipynb',\n",
       " 'star-wars-chatbot.ipynb',\n",
       " 'starwars-chatbot-nlp-application.ipynb',\n",
       " 'steeldefect-sgment.ipynb',\n",
       " 'stock-prediction-pytorch.ipynb',\n",
       " 'super-mario-bros-ddqn-1-3.ipynb',\n",
       " 'super-mario-bros-ddqn-w7s3v2.ipynb',\n",
       " 't-cnicas-de-an-lisis.ipynb',\n",
       " 'tarea-3-adaline.ipynb',\n",
       " 'tarea-8-artemio-padilla-aprendizaje-profundo.ipynb',\n",
       " 'tarea-8-mart-nez-ostoa-n-stor.ipynb',\n",
       " 'tarea8-juan-pablo-hernandez-lozano.ipynb',\n",
       " 'tarea8-traductor-benito-franco.ipynb',\n",
       " 'template.ipynb',\n",
       " 'test-all-efficientnet-model-b0-b7.ipynb',\n",
       " 'text-analysis-on-job-title.ipynb',\n",
       " 'textworld-nlp-approaches.ipynb',\n",
       " 'tf-with-efficientnet-train.ipynb',\n",
       " 'tfidf.ipynb',\n",
       " 'the-movies-dataset-clustering-comparison.ipynb',\n",
       " 'tps-06-autokeras.ipynb',\n",
       " 'tps-may-eda-visualization-with-plotly-mljar.ipynb',\n",
       " 'trabajo-practico-n-3-ia.ipynb',\n",
       " 'trabalho-chatbot.ipynb',\n",
       " 'trabalho-de-estatistica-iii-final.ipynb',\n",
       " 'train-swin-t-pytorch-lightning.ipynb',\n",
       " 'transfer-learning-with-inception-v3.ipynb',\n",
       " 'tugas-clustering-119290061.ipynb',\n",
       " 'tugas-clustering.ipynb',\n",
       " 'underwater-segmentation-prediction-v.ipynb',\n",
       " 'underwater-segmentation-prediction-vi.ipynb',\n",
       " 'unet-baseline-train.ipynb',\n",
       " 'unet-baseline.ipynb',\n",
       " 'unet-image-segmentation.ipynb',\n",
       " 'unet2020-with-epitomes.ipynb',\n",
       " 'univerzita-karlova-z-po-tov-program.ipynb',\n",
       " 'usa-arrests-with-k-means-clustering.ipynb',\n",
       " 'used-car-data-set-bmw.ipynb',\n",
       " 'using-segmentation-for-sci-and-using-unet.ipynb',\n",
       " 'vandaele-florian-advanced-ai-labo-examen-15-12.ipynb',\n",
       " 'vina-gustirani-119290077-tugas-clustering.ipynb',\n",
       " 'windy-gridworld-with-king-s-moves-greedypolicy.ipynb',\n",
       " 'wine-clustering-using-fcmeans.ipynb',\n",
       " 'world-happiness-report-eda-logistic-regression.ipynb',\n",
       " 'xception-keras.ipynb',\n",
       " 'xgboost-and-data-viz-fa-ga.ipynb',\n",
       " 'xrays-multi-mobilenetv2.ipynb',\n",
       " 'xrays-multi-nasnetmobile.ipynb',\n",
       " 'yolo-random-object-detection.ipynb',\n",
       " 'yolov1-implementation-with-pytorch.ipynb',\n",
       " 'yosan-at-taufiq-119290003-tugasclusteringiot.ipynb',\n",
       " 'zidniy-qonitah-k-119290052-tugas-clustering.ipynb']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List_non_en_ntb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(List_non_en_ntb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell-type</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd import numpy as np import ...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>markdown</td>\n",
       "      <td>try to overfit more pls upvote if you fork lik...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>markdown</td>\n",
       "      <td>sub1 0 869</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>markdown</td>\n",
       "      <td>credit very simple code with score 0 886 by ay...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd import numpy as np from sk...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344966</th>\n",
       "      <td>code</td>\n",
       "      <td>POI_data = gpd.read_file(\"../input/geospatial...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344967</th>\n",
       "      <td>markdown</td>\n",
       "      <td>next we create a map from all four geodatafram...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344968</th>\n",
       "      <td>code</td>\n",
       "      <td>ax = counties.plot(figsize=(10,10), color='no...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344969</th>\n",
       "      <td>markdown</td>\n",
       "      <td>it looks like the northeastern part of the sta...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344970</th>\n",
       "      <td>markdown</td>\n",
       "      <td>have questions or comments visit the course di...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332605 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cell-type                                             source  \\\n",
       "0           code  import pandas as pd import numpy as np import ...   \n",
       "1       markdown  try to overfit more pls upvote if you fork lik...   \n",
       "2       markdown                                         sub1 0 869   \n",
       "3       markdown  credit very simple code with score 0 886 by ay...   \n",
       "4           code  import pandas as pd import numpy as np from sk...   \n",
       "...          ...                                                ...   \n",
       "344966      code   POI_data = gpd.read_file(\"../input/geospatial...   \n",
       "344967  markdown  next we create a map from all four geodatafram...   \n",
       "344968      code   ax = counties.plot(figsize=(10,10), color='no...   \n",
       "344969  markdown  it looks like the northeastern part of the sta...   \n",
       "344970  markdown  have questions or comments visit the course di...   \n",
       "\n",
       "                                               title                     tag  \n",
       "0       0-9-try-better-parameters-better-score.ipynb              regression  \n",
       "1       0-9-try-better-parameters-better-score.ipynb              regression  \n",
       "2       0-9-try-better-parameters-better-score.ipynb              regression  \n",
       "3       0-9-try-better-parameters-better-score.ipynb              regression  \n",
       "4       0-9-try-better-parameters-better-score.ipynb              regression  \n",
       "...                                              ...                     ...  \n",
       "344966                          your-first-map.ipynb  reinforcement learning  \n",
       "344967                          your-first-map.ipynb  reinforcement learning  \n",
       "344968                          your-first-map.ipynb  reinforcement learning  \n",
       "344969                          your-first-map.ipynb  reinforcement learning  \n",
       "344970                          your-first-map.ipynb  reinforcement learning  \n",
       "\n",
       "[332605 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop notebooks where cells are considered as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['stocks-reinforcement-learning-ensemble.ipynb',\n",
       "       'world-happiness-and-65-world-indexes.ipynb',\n",
       "       'xlm-roberta-base.ipynb', 'yolov5-vinbigdata.ipynb'], dtype='<U44')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = raw_df[raw_df['cell-type']=='code']\n",
    "l=[]\n",
    "for i in data.index:\n",
    "        if data.loc[i]['source'].startswith(\"['\") and data.loc[i]['source'].endswith(\"']\"):\n",
    "            l.append(data.loc[i]['title'])\n",
    "np.unique(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ntb in l:\n",
    "    raw_df.drop(raw_df.index[raw_df['title'] == ntb], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.to_pickle(DATA_PATH + \"text_data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49ab456e11cde720218fba409a85456f40f210cf294d5c8f56d5f4fb69af5c6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
