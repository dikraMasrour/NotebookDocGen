{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Training word2vec model for moroccan and algerian dialect"
=======
    "## Predicting ad positioning using Q-Learning"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92164cd7",
   "metadata": {},
   "source": [
    "ğŸª„Imports data from the Icetea package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import glob"
=======
   "metadata": {},
   "source": [
    "Placement of ads on website is the primary problem for companies that operate on ad revenue. The position where the ad is placed plays pivotal role on whether or not the ad will be clicked. Here we have the following choices:\n",
    "\t1. Place them randomly, or\n",
    "\t2. Place the ad on the same position\n",
    "\n",
    "The problem with placing the ad on the same position is the user, after a certain time, will start ignoring the space since he's used to seeing ad at the place, he will end up ignoring that particular position hereafter. Hence, this will reduce the number of clicks on ads. The problem with the former option, placing them randomly, is it wouldn't take optimal positions into consideration. For instance, text beside images are viewed higher number of times than those text which are placed at a distance. It is infeasible to go through every website and repeat the procedure. \n",
    "\n",
    "Solution: Reinforcement Learning\n",
    "Using Reinforcement Learning we can approximate the human behavior. \n",
    "\n",
    "Why Reinforcement Learning? \n",
    "We cannot use traditional Machine Learning here, since it requires:\n",
    "\t1. Huge data\n",
    "\t2. Features\n",
    "\t3. Tuning of many hyperparameters\n",
    "And we neither have huge data, nor features. The only data we have is the position of the baner/ad and whether or not it was clicked. We will use this dataset from Kaggle: https://www.kaggle.com/akram24/ads-ctr-optimisation. We will solve this problem using Q-Learning. The reason for using Q-Learning here is :\n",
    "\t1. It is model free, so it doesn't require to know all the states.\n",
    "\t2. Intuitive to understand, and converges faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8db08a",
   "metadata": {},
   "source": [
    "ğŸª„Import routine data from Python arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import routines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our environment will be the dataset. It contains 10 ads position per row having values either 1, when the ad is clicked, or 0 when it is not. Every row can be considered as a state in the space, considering it kind of a navigation across multiple pages (on website, for instance) Lets load the dataset and visualize the first few rows"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "54cbb3a1",
   "metadata": {},
   "source": [
    "ğŸª„Loads data from one - drive dataset."
=======
   "id": "3670d521",
   "metadata": {},
   "source": [
    "ğŸª„Reads the header of the environment and parses the data as a CSV."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 2,
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>comments</th>\n",
=======
       "      <th>Ad 1</th>\n",
       "      <th>Ad 2</th>\n",
       "      <th>Ad 3</th>\n",
       "      <th>Ad 4</th>\n",
       "      <th>Ad 5</th>\n",
       "      <th>Ad 6</th>\n",
       "      <th>Ad 7</th>\n",
       "      <th>Ad 8</th>\n",
       "      <th>Ad 9</th>\n",
       "      <th>Ad 10</th>\n",
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>Ø¹Ø§Ø¯Ùˆ Ø§Ù„Ù†Ø§Ø³ ÙŠØªØ¨Ø§ÙƒØ§Ùˆ Ø¨Ø¯ÙŠØª Ù†Ù‡Ø¯Ø± Ù…Ù† Ù‚Ù„Ø¨ÙŠ ØªÙ‚ÙˆÙ„ Ù†Ù‡Ø¯...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø¨ÙƒÙŠØª Ø§Ù„Ù†Ø§Ø³ ÙƒØ§Ù…Ù„ Ø³ÙƒØªÙˆ ØªØ®Ù„Ø¹Øª ÙÙŠ Ø±ÙˆØ­ÙŠ ØªÙ‚ÙˆÙ„ ÙƒÙ†Øª Ù†Ù†ÙˆÙ…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù†Ø§Ø¶Ùˆ ï­­ïºØ¹ Ø³Ù„Ù…Ùˆ Ø¹Ù„ÙŠØ§ Ùˆ ÙŠÙ‡Ø¯Ø±Ùˆ Ù…Ø¹Ø§ÙŠØ§ Ù†Øµ Ø¨ÙƒØ§ Ùˆ Ù†Øµ Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø¹Ø±Ø¶ÙˆÙ†Ø§ Ù„Ù„Ø¹Ø´Ø§ Ùˆ ÙƒØ§Ù† Ù„Ø¹Ø´Ø§ ÙŠÙƒÙÙŠ Ù„ÙŠØ²Ø§ï»§Ú¢ÙŠØªÙŠ ï­­ïºØ¹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø¬ÙˆØ²Øª Ø§ÙŠØ§Ù…Ø§Øª Ø±ÙˆØ¹Ø© Ù…Ø§ Ù†Ù†Ø³Ø§Ù‡Ø§Ø´ Ø·ÙˆÙ„ Ø­ÙŠØ§ØªÙŠ</td>\n",
=======
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                                            comments\n",
       "0   Ø¹Ø§Ø¯Ùˆ Ø§Ù„Ù†Ø§Ø³ ÙŠØªØ¨Ø§ÙƒØ§Ùˆ Ø¨Ø¯ÙŠØª Ù†Ù‡Ø¯Ø± Ù…Ù† Ù‚Ù„Ø¨ÙŠ ØªÙ‚ÙˆÙ„ Ù†Ù‡Ø¯...\n",
       "1   Ø¨ÙƒÙŠØª Ø§Ù„Ù†Ø§Ø³ ÙƒØ§Ù…Ù„ Ø³ÙƒØªÙˆ ØªØ®Ù„Ø¹Øª ÙÙŠ Ø±ÙˆØ­ÙŠ ØªÙ‚ÙˆÙ„ ÙƒÙ†Øª Ù†Ù†ÙˆÙ…\n",
       "2  Ù†Ø§Ø¶Ùˆ ï­­ïºØ¹ Ø³Ù„Ù…Ùˆ Ø¹Ù„ÙŠØ§ Ùˆ ÙŠÙ‡Ø¯Ø±Ùˆ Ù…Ø¹Ø§ÙŠØ§ Ù†Øµ Ø¨ÙƒØ§ Ùˆ Ù†Øµ Ù„...\n",
       "3         Ø¹Ø±Ø¶ÙˆÙ†Ø§ Ù„Ù„Ø¹Ø´Ø§ Ùˆ ÙƒØ§Ù† Ù„Ø¹Ø´Ø§ ÙŠÙƒÙÙŠ Ù„ÙŠØ²Ø§ï»§Ú¢ÙŠØªÙŠ ï­­ïºØ¹\n",
       "4              Ø¬ÙˆØ²Øª Ø§ÙŠØ§Ù…Ø§Øª Ø±ÙˆØ¹Ø© Ù…Ø§ Ù†Ù†Ø³Ø§Ù‡Ø§Ø´ Ø·ÙˆÙ„ Ø­ÙŠØ§ØªÙŠ"
      ]
     },
     "execution_count": 26,
=======
       "   Ad 1  Ad 2  Ad 3  Ad 4  Ad 5  Ad 6  Ad 7  Ad 8  Ad 9  Ad 10\n",
       "0     1     0     0     0     1     0     0     0     1      0\n",
       "1     0     0     0     0     0     0     0     0     1      0\n",
       "2     0     0     0     0     0     0     0     0     0      0\n",
       "3     0     1     0     0     0     0     0     1     0      0\n",
       "4     0     0     0     0     0     0     0     0     0      0"
      ]
     },
     "execution_count": 2,
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "path = r'C:\\\\Users\\\\zbook\\\\OneDrive - UIR\\\\UIR\\\\S8\\\\AutoTranslate\\\\word2vec_trainingdata'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df_elem = pd.read_csv(filename, index_col=None, header=0, on_bad_lines='skip')\n",
    "    li.append(df_elem)\n",
    "\n",
    "df = pd.concat(li, ignore_index=True)\n",
    "df.head()"
=======
    "env = pd.read_csv('Ads_CTR_Optimisation.csv')\n",
    "env.head()"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "7ac1b13a",
   "metadata": {},
   "source": [
    "ğŸª„shape of dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
=======
   "metadata": {},
   "source": [
    "## Random policy\n",
    "\n",
    "If we were to not have Q-Learning, we would place the ads randomly at given positions. We will now simulate the same.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e0a30",
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115226, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "df.shape"
=======
    "ğŸª„total rewards earned reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward collected: 1245\n"
     ]
    }
   ],
   "source": [
    "# total rewards earned\n",
    "reward = 0\n",
    "# random policy: for every state, choose a random\n",
    "# position for displaying the ad\n",
    "for x in range(len(env)):\n",
    "    action = np.random.randint(0, 10)\n",
    "    # if the guess was correct, increase the reward\n",
    "    if env.values[x][action] == 1:\n",
    "        reward += 1\n",
    "print(\"Reward collected: {}\".format(reward))"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "##### Tokenizing"
=======
    "## Using Max Policy\n",
    "Another question we might ask, is to display the ad where it is clicked the most number of times. For instance, there might be a certain position where the ad clicked with a higher probability. Since the values of the rows is either 1 or 0, we can sum across the columns and count the number of times ad in the position was clicked. "
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "159c98b3",
   "metadata": {},
   "source": [
    "ğŸª„Tokenize the comments."
=======
   "id": "5e5bba82",
   "metadata": {},
   "source": [
    "ğŸª„counts of the most common values in the environment."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [Ø¹Ø§Ø¯Ùˆ, Ø§Ù„Ù†Ø§Ø³, ÙŠØªØ¨Ø§ÙƒØ§Ùˆ, Ø¨Ø¯ÙŠØª, Ù†Ù‡Ø¯Ø±, Ù…Ù†, Ù‚Ù„Ø¨ÙŠ, Øª...\n",
       "1         [Ø¨ÙƒÙŠØª, Ø§Ù„Ù†Ø§Ø³, ÙƒØ§Ù…Ù„, Ø³ÙƒØªÙˆ, ØªØ®Ù„Ø¹Øª, ÙÙŠ, Ø±ÙˆØ­ÙŠ, ØªÙ‚Ùˆ...\n",
       "2         [Ù†Ø§Ø¶Ùˆ, ï­­ïºØ¹, Ø³Ù„Ù…Ùˆ, Ø¹Ù„ÙŠØ§, Ùˆ, ÙŠÙ‡Ø¯Ø±Ùˆ, Ù…Ø¹Ø§ÙŠØ§, Ù†Øµ, Ø¨...\n",
       "3         [Ø¹Ø±Ø¶ÙˆÙ†Ø§, Ù„Ù„Ø¹Ø´Ø§, Ùˆ, ÙƒØ§Ù†, Ù„Ø¹Ø´Ø§, ÙŠÙƒÙÙŠ, Ù„ÙŠØ²Ø§ï»§Ú¢ÙŠØªÙŠ,...\n",
       "4             [Ø¬ÙˆØ²Øª, Ø§ÙŠØ§Ù…Ø§Øª, Ø±ÙˆØ¹Ø©, Ù…Ø§, Ù†Ù†Ø³Ø§Ù‡Ø§Ø´, Ø·ÙˆÙ„, Ø­ÙŠØ§ØªÙŠ]\n",
       "                                ...                        \n",
       "115221    [Ø´ÙƒØ±Ø§, Ù„Ù‚Ø¯, Ø§Ø³ØªÙ…ØªØ¹Øª, Ø¨Ù‡Ø°Ø§, Ø§Ù„ÙÙŠØ¯ÙŠÙˆ, ÙƒØ«ÙŠØ±Ø§, Ø®Ø¨ÙŠ...\n",
       "115222    [ÙÙŠØ¯ÙŠÙˆ, Ù…Ù…ØªØ¹, ÙˆØ§Ù„Ù„Ù‡, Ø±ÙˆÙˆÙˆØ¹Ø©, ÙŠØ¹Ø·ÙŠÙƒ, Ø§Ù„ØµØ­Ø©, Ø®ÙˆÙŠ...\n",
       "115223            [Ø¨Ø±Ø§Ø§Ø§ÙÙˆ, Ø¹Ù„ÙŠÙƒ, ØªØ³ØªØ§Ù‡Ù„, Ø§Ù„Ø´Ù‡Ø±Ø©, Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©]\n",
       "115224    [Ø§Ù„Ù„Ù‡, ÙŠØ¨Ø§Ø±Ùƒ, ØŒ, Ù…Ø§, Ø´Ø§Ø¡, Ø§Ù„Ù„Ù‡, Ø®ÙˆÙŠØ§, Ø®Ø¨ÙŠØ¨ÙŠØ³Ù‘Ø±...\n",
       "115225                     [Ø£ÙØ¶Ù„, ØµØ§Ù†Ø¹, Ù…Ø­ØªÙˆÙ‰, ÙÙŠ, Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±]\n",
       "Name: comments, Length: 115226, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenized = df.comments.apply(nltk.word_tokenize)\n",
    "df_tokenized"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    counts\n",
       "ad        \n",
       "1     1703\n",
       "2     1295\n",
       "3      728\n",
       "4     1196\n",
       "5     2695\n",
       "6      126\n",
       "7     1112\n",
       "8     2091\n",
       "9      952\n",
       "10     489"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicked_counts = env.values.sum(axis=0)\n",
    "counts = pd.DataFrame({\"ad\": np.arange(1, 11), \"counts\": clicked_counts})\n",
    "counts.set_index(\"ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which indicates ad 5 was clicked 2695 times. So if we were to always place an ad on position 5, it would be click around 2695 times. But can we do better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Policy Iteration (Dynamic Programming) "
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "##### Initializing word2vec model"
=======
   "id": "1be4ab47",
   "metadata": {},
   "source": [
    "ğŸª„Get action space from the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total episodes trained: 11\n"
     ]
    }
   ],
   "source": [
    "action_space = np.arange(0, 100)\n",
    "# starting with random policy, choose a random choice for\n",
    "# every state in the environment\n",
    "state_size = len(env)\n",
    "policy = [random.choice(action_space) for x in range(state_size)]\n",
    "# will take random action for the first time\n",
    "first_time = True\n",
    "small_change = 1e-20\n",
    "gamma = 0.9\n",
    "episodes = 0\n",
    "max_episodes = 10\n",
    "\n",
    "V = dict()\n",
    "# last positions reward will be 1\n",
    "V[10000] = 1\n",
    "\n",
    "# initially the value function for all states\n",
    "# will be random values close to zero\n",
    "for i in range(state_size):\n",
    "    V[i] = np.random.random()\n",
    "\n",
    "while episodes < max_episodes:\n",
    "    # policy evaluation\n",
    "    while True:\n",
    "        if episodes > max_episodes:\n",
    "            break\n",
    "        episodes += 1\n",
    "        if episodes % 100 == 0:\n",
    "            print(\"Current episode: {}\".format(episodes))\n",
    "        biggest_change = 0\n",
    "        # loop through every state present\n",
    "        for state in range(state_size):\n",
    "            old_V = V[state]\n",
    "            # take random action according to policy\n",
    "            action = policy[state]\n",
    "            new_state = state + 1\n",
    "            reward = env.values[state][action]\n",
    "            V[state] = reward + gamma * V[new_state]\n",
    "            biggest_change = max(biggest_change, abs(V[state] - old_V))\n",
    "        if biggest_change < small_change:\n",
    "            break\n",
    "            \n",
    "    # policy improvement\n",
    "    policy_changed = False\n",
    "    for state in range(state_size):\n",
    "        best_val = -np.inf\n",
    "        best_action = -1\n",
    "        for action in action_space:\n",
    "            new_state = state + 1\n",
    "            reward = env.values[state][action]\n",
    "            future_reward = reward + gamma * V[new_state]\n",
    "            if future_reward > best_val:\n",
    "                best_val = future_reward\n",
    "                best_action = action\n",
    "        assert best_action != -1\n",
    "        if policy[state] != best_action:\n",
    "            policy_changed = True\n",
    "        policy[state] = best_action\n",
    "\n",
    "    if not policy_changed:\n",
    "        break\n",
    "print(\"Total episodes trained: {}\".format(episodes))"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "7a53ba37",
   "metadata": {},
   "source": [
    "ğŸª„Create a new word2Vec model for use with the HMM module."
=======
   "id": "e08cf300",
   "metadata": {},
   "source": [
    "ğŸª„total rewards earned reward = 0"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(window=5, min_count=2, workers=2)"
=======
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward collected: 10000\n"
     ]
    }
   ],
   "source": [
    "# total rewards earned\n",
    "reward = 0\n",
    "# random policy: for every state, choose a random\n",
    "# position for displaying the ad\n",
    "for x in range(len(env)):\n",
    "    action = policy[x]\n",
    "    # if the guess was correct, increase the reward\n",
    "    if env.values[x][action] == 1:\n",
    "        reward += 1\n",
    "print(\"Reward collected: {}\".format(reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Q-Learning\n",
    "\n"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "##### Building vovab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec978ed",
   "metadata": {},
   "source": [
    "ğŸª„Builds the vocabulary from the input dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(df_tokenized, progress_per=5)"
=======
   "id": "6e2c2a12",
   "metadata": {},
   "source": [
    "ğŸª„learning rate based on the current state of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using q-learning\n",
    "states = len(env)\n",
    "actions = 10\n",
    "q_table = np.zeros((states, actions))\n",
    "\n",
    "learning_rate = 0.7\n",
    "# gamma = 0.618\n",
    "gamma = 0.9\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01\n",
    "max_episodes = 100"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "e98d07be",
   "metadata": {},
   "source": [
    "ğŸª„The number of iterations done on the whole dataset by default it is 5 model.epochs"
=======
   "id": "f81ea296",
   "metadata": {},
   "source": [
    "ğŸª„Randomizes a number to select whether or not to expolit"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs being the number of iterations done on the whole dataset, by default it is 5\n",
    "model.epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5614789d",
   "metadata": {},
   "source": [
    "ğŸª„Train a model by tokenizing the corpus count and number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4727130, 5645515)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(df_tokenized, total_examples=model.corpus_count, epochs=model.epochs)"
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploit(eps):\n",
    "    \"\"\"Randomizes a number to select\n",
    "    whether or not to expolit\"\"\"\n",
    "    return np.random.uniform() > eps\n",
    "\n",
    "def random_action():\n",
    "    return np.random.randint(0, 10)"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "##### Saving model"
=======
   "id": "14bae885",
   "metadata": {},
   "source": [
    "ğŸª„Calculates the reward value for each episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Episode: 50\n"
     ]
    }
   ],
   "source": [
    "reward = 0\n",
    "for episode in range(max_episodes):\n",
    "    epsilon *= 2\n",
    "    if episode % 50 == 0:\n",
    "        print(\"Episode: {}\".format(episode))\n",
    "    for state in range(states):\n",
    "        if exploit(epsilon):\n",
    "            action = random_action()\n",
    "        else:\n",
    "            action = np.argmax(q_table[state])\n",
    "        r = env.values[state][action]\n",
    "        reward += r\n",
    "        q_table[state][action] += learning_rate*(r + gamma*np.max(q_table[state, :]) - q_table[state][action])\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate*episode)"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "fc33fb1b",
   "metadata": {},
   "source": [
    "ğŸª„Save the model s file - > vector_mor_dz. model object."
=======
   "id": "8decf96b",
   "metadata": {},
   "source": [
    "ğŸª„Test function for rewards"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./word2vec_mor_dz.model')"
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward collected: 1703\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "rewards = 0\n",
    "for state in range(states):\n",
    "    best_action = np.argmax(q_table[state, :])\n",
    "    r = env.values[state][best_action]\n",
    "    rewards += r\n",
    "print(\"Reward collected: {}\".format(rewards))"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "##### Testing"
=======
   "id": "f3da951d",
   "metadata": {},
   "source": [
    "ğŸª„Returns the sum of values along axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 6, ..., 4, 6, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.values.sum(axis=1)"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "ebe68aeb",
   "metadata": {},
   "source": [
    "ğŸª„Get vector of values in the WV model"
=======
   "id": "99927f25",
   "metadata": {},
   "source": [
    "ğŸª„Get the current state of the graph."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.30374986,  0.07175432, -1.9774907 ,  0.8653471 ,  1.0058571 ,\n",
       "        0.03052483,  1.6197143 , -1.0898234 ,  1.1693029 ,  0.96499985,\n",
       "       -1.1037531 , -1.5497943 ,  1.9381372 ,  1.0726736 ,  0.7137537 ,\n",
       "       -1.9590017 , -0.7012492 , -0.37255132, -0.19502258, -0.01550069,\n",
       "        0.30475372,  0.02588587, -0.10248473,  0.75695884,  0.87948567,\n",
       "       -1.8181672 ,  0.20955311, -0.29015642,  0.6445919 , -1.2174771 ,\n",
       "        2.6708517 , -0.37695837,  1.6182309 , -0.16528021, -1.2222136 ,\n",
       "        0.04739395,  0.03246354,  1.685888  ,  0.8174039 , -1.4625372 ,\n",
       "       -1.1201082 ,  0.2508373 ,  1.0266021 , -0.27731118,  0.01646691,\n",
       "       -1.3282051 ,  0.6850137 ,  0.15229063,  0.57460415,  0.7096181 ,\n",
       "        0.83873975, -0.14124483, -0.05335499, -2.1376112 ,  0.7597384 ,\n",
       "        0.00964276,  0.32463962,  1.6149795 ,  0.25036755, -0.84656155,\n",
       "       -0.11048245, -0.41262317,  1.1813644 , -0.61122257, -1.9603467 ,\n",
       "        0.73217666, -0.12566723,  1.2469335 , -1.2762504 ,  1.3140593 ,\n",
       "       -0.0808326 ,  0.67132723,  1.4991429 ,  1.59795   , -0.03220373,\n",
       "       -0.8748432 , -0.5941907 , -0.64879906, -0.08678758,  1.7098435 ,\n",
       "       -0.5889559 , -0.64070845,  0.19907294,  0.086163  , -0.30998918,\n",
       "       -1.4234908 ,  0.7986347 , -0.69719934, -0.9008635 ,  0.01687654,\n",
       "       -0.3002783 ,  0.44608024,  1.938321  , -0.72941923,  0.94874084,\n",
       "       -0.19638109,  1.2977958 ,  0.91942734,  0.67938447, -0.65222347],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('Ø§Ù„ÙÙŠØ¯ÙŠÙˆ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76afdc01",
   "metadata": {},
   "source": [
    "ğŸª„size of vector in Wv."
=======
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b29ca1c",
   "metadata": {},
   "source": [
    "ğŸª„Get the current state of the graph."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67935737",
   "metadata": {},
   "source": [
    "ğŸª„Return the most similar model to the Wv - L divergence."
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5f3cca7",
   "metadata": {},
   "source": [
    "ğŸª„Get the current state of the graph."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ø§Ù„ÙØ¯ÙŠÙˆ', 0.8424222469329834),\n",
       " ('Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª', 0.8212994337081909),\n",
       " ('Ø§Ù„ÙŠÙˆÙ…', 0.809577226638794),\n",
       " ('Ø§Ù„ÙˆØµÙØ©', 0.8092324137687683),\n",
       " ('Ø§Ù„Ù…Ø®ØªÙ„Ø³ÙŠÙ†', 0.7842799425125122),\n",
       " ('Ù„ÙÙŠØ¯ÙŠÙˆ', 0.7826778888702393),\n",
       " ('Ø§Ù„Ù…Ù†Ø¨Ø±', 0.7803176641464233),\n",
       " ('Ø§Ù„Ø­Ù„Ù‚Ø©', 0.7770587205886841),\n",
       " ('Ø§Ù„ÙÙŠØ¯ÙŠÙˆØ§', 0.7731214761734009),\n",
       " ('Ø§Ù„Ø§ØºÙ†ÙŠØ©', 0.7693439722061157)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('Ø§Ù„ÙÙŠØ¯ÙŠÙˆ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309c0dc",
   "metadata": {},
   "source": [
    "ğŸª„Return the value of the most similar model."
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "055467f8",
   "metadata": {},
   "source": [
    "ğŸª„Make a dataframe of random values for the given list of values."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ØµØ­Ø©', 0.957695722579956),\n",
       " ('Ø§Ù„ØµØ­Ù‡', 0.9494235515594482),\n",
       " ('ØµØ­Ù‡', 0.9477626085281372),\n",
       " ('Ø§Ø§ØµØ­Ø©', 0.9430625438690186),\n",
       " ('Ø§Ù„Ø¹Ø§ÙÙŠÙ‡', 0.938389778137207),\n",
       " ('Ø§Ù„ØµØ­Ø§', 0.934445858001709),\n",
       " ('Ù…Ø§ØªØªÙ…Ù†Ù‰', 0.9239757657051086),\n",
       " ('Ø§Ù„Ø¹Ø§ÙÙŠØ©', 0.921890139579773),\n",
       " ('ÙŠÙ…Ù†ÙŠÙƒ', 0.921332597732544),\n",
       " ('Ù…Ø§ØªØªÙ…Ù†Ø§', 0.920365035533905)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('Ø§Ù„ØµØ­Ø©')"
=======
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list = [np.random.randint(0, 10) for x in range(10000)]\n",
    "env = np.zeros((10000, 100))\n",
    "i = 0\n",
    "for x in rand_list:\n",
    "    env[i][x] = 1\n",
    "    i += 1\n",
    "env = pd.DataFrame(env)"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "fd9e3e4d",
   "metadata": {},
   "source": [
    "ğŸª„Return the value of the most similar model."
=======
   "id": "8f93ae39",
   "metadata": {},
   "source": [
    "ğŸª„Sum the values of the environment variables."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 31,
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "[('Ø³ÙˆØ¡', 0.8432469964027405),\n",
       " ('Ø´Ø±', 0.8258323669433594),\n",
       " ('ÙØ­ÙŠØ§ØªÙ‡Ø§', 0.8234294056892395),\n",
       " ('Ø§Ø¹ØªØ¯Ù‰', 0.8075923323631287),\n",
       " ('Ù…ÙƒØ±ÙˆÙ‡', 0.8055546283721924),\n",
       " ('ÙˆØ´Ø¹Ø¨Ù†Ø§', 0.7985508441925049),\n",
       " ('Ø§Ù…Ø§Ù†ÙŠÙƒÙ…', 0.7867958545684814),\n",
       " ('ÙŠØ´Ø§ÙÙŠ', 0.7866781949996948),\n",
       " ('Ù…Ù‚Ø§Ù…Ù‡Ø§', 0.7856148481369019),\n",
       " ('Ø§Ù„Ø®ÙŠØ±', 0.7848873138427734)]"
      ]
     },
     "execution_count": 42,
=======
       "10000.0"
      ]
     },
     "execution_count": 31,
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "model.wv.most_similar('Ø®ÙŠØ±')"
=======
    "env.sum().sum()"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "40771824",
   "metadata": {},
   "source": [
    "ğŸª„Return the similarity between two words."
=======
   "id": "dccad063",
   "metadata": {},
   "source": [
    "ğŸª„The value of the first environment entry in the list of values."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
=======
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.values[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef64e1",
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55149865"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1='Ø§Ù„Ø®ÙŠØ±', w2='ØµØ¨Ø§Ø­')"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e0683708a40e5e31be6eca1343e37f88fae9f778fb3fd433a047241db249add"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.8.6"
=======
   "version": "3.6.5"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
